{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resource Watch Query Tool (beta) - Bahasa Indonesian.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qveHN6SggdBy",
        "ga3qddmXvZ_K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhAZQx4gmV2C",
        "colab_type": "text"
      },
      "source": [
        "![alt text][logo]\n",
        "\n",
        "[logo]:https://wri-public-data.s3.amazonaws.com/resourcewatch/18_LOGO_ResourceWatch/18_LOGO_ResourceWatch_PB.png \"Logo Title Text 2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Ii6bzQac87",
        "colab_type": "text"
      },
      "source": [
        "#Resource Watch Query Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGPUAy1fmMvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title # **Pemasangan Alat Bantu** { display-mode: \"form\" }\n",
        "#@markdown ###Tekan tombol “play” di sebelah kiri untuk memasang alat bantu bagi analisis Anda.\n",
        "!pip install geojson -q\n",
        "import pandas as pd\n",
        "import codecs\n",
        "import requests\n",
        "import random\n",
        "import urllib.parse\n",
        "import warnings\n",
        "import numpy as np\n",
        "import json\n",
        "import shapely.wkt\n",
        "import geojson\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "!pip install LMIPy -q\n",
        "import LMIPy\n",
        "import sys\n",
        "print('Selesai menginstal modul!')\n",
        "print('Anda dapat beralih ke sel berikutnya.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qveHN6SggdBy",
        "colab_type": "text"
      },
      "source": [
        "#Querying Data within a Boundary Area (Optional)\n",
        "\n",
        "Are you interested in global data or data for a specific country or region? For global data, you can skip this section.\n",
        "\n",
        "If you are interested in a specific country or region, please complete this section. Please note that only point data can be analyzed within a boundary area. You cannot analyze polygon data within a boundary area with this tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4V2yZN_51r",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ## Choose the Dataset that will Define Your Boundary Area\n",
        "#@markdown You can type the word **national** in the 'shapefile_dataset_id' field if you would like to do a national-level analysis. You do not need to enter anything in the 'shapefile_layer_id' for a national-level analysis.\n",
        "#@markdown \n",
        "#@markdown If you would like to use boundaries from a different vector dataset on Resource Watch, find the dataset that contains the boundary you want to use, navigate to its metadate page, and copy the dataset ID into the 'shapefile_dataset_id' field, below. You can use boundaries from any polygon (non-point) vector dataset on Resource Watch.\n",
        "#@markdown \n",
        "#@markdown If you are interested in sub-national administrative boundaries, you may want to use the Subnational Political Boundaries dataset (http://bit.ly/2YZov2Y), which has the following dataset ID:\n",
        "#@markdown \n",
        "#@markdown &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Politcial-Boundaries-GADM-adminitrative-level-1-1490086842541\n",
        "#@markdown \n",
        "#@markdown Here are some additional example vector dataset IDs that you might want to use for your boundary area:\n",
        "#@markdown *   World Database on Protected Areas (http://bit.ly/2Z5ucfE): de452a4c-a55c-464d-9037-8c3e9fe48365 \n",
        "#@markdown *   Maritime Boundaries (http://bit.ly/2YYCm9L): bf5877eb-399a-4237-b510-b1d41049e3bc\n",
        "#@markdown \n",
        "#@markdown Once you have entered your dataset ID, you can push the play button on the left to see a list of layers available for this dataset. Choose the layer that contains your boundary area, and enter the id in the 'shapefile_layer_id' field and push play again.\n",
        "#@markdown \n",
        "\n",
        "\n",
        "#@markdown ###Please enter a dataset ID, then push the play button on the left.\n",
        "\n",
        "shapefile_dataset_id = None\n",
        "shapefile_layer_id = None\n",
        "shapefile_layer_name = None\n",
        "shapefile_ds_name = None\n",
        "try:\n",
        "  #Get vector dataset\n",
        "  shapefile_dataset_id = \"\" #@param {type:\"string\"}\n",
        "  shapefile_dataset_id = shapefile_dataset_id.strip()\n",
        "  if shapefile_dataset_id == 'national':\n",
        "    country_analysis = 'Y'\n",
        "    print('Analyzing data at the national-level.')\n",
        "    print('Anda dapat beralih ke sel berikutnya.')  \n",
        "  else:\n",
        "    country_analysis = 'N'\n",
        "    if shapefile_dataset_id == ('de452a4c-a55c-464d-9037-8c3e9fe48365' or 'World-Database-on-Protected-Areas-Global-1490086842549'):\n",
        "      wdpa = 'Y'\n",
        "    else:\n",
        "      wdpa = 'N'\n",
        "    #Get name from raster dataset\n",
        "    url = 'https://api.resourcewatch.org/dataset/'+shapefile_dataset_id+'?includes=layer,metadata'\n",
        "    r = requests.get(url)\n",
        "    for ds in r.json()['data']['attributes']['metadata']:\n",
        "      if ds['attributes']['application']=='rw':\n",
        "        shapefile_ds_name = ds['attributes']['name']\n",
        "    print('Analyzing dataset: {}'.format(shapefile_ds_name))\n",
        "    #Get layers from shapefile dataset\n",
        "    print('Available layers for '+shapefile_ds_name +' dataset:')\n",
        "    layer_dict = dict()\n",
        "    layers = r.json()['data']['attributes']['layer']\n",
        "    for layer in layers:\n",
        "      if layer['attributes']['application']==['rw']:\n",
        "        analysis_layer_name = layer['attributes']['name']\n",
        "        analysis_layer_id =  layer['id']\n",
        "        layer_dict[analysis_layer_id]=analysis_layer_name\n",
        "        print('     '+analysis_layer_name+' - Layer ID: '+analysis_layer_id)\n",
        "        #print('       -Layer ID: '+analysis_layer_id)\n",
        "    shapefile_layer_id = \"\"#@param {type:\"string\"}\n",
        "    if shapefile_layer_id==\"\":\n",
        "      print(\"Please enter a layer ID from these options, and push play again.\")\n",
        "    else:\n",
        "      try:\n",
        "        shapefile_layer_id=shapefile_layer_id.strip()\n",
        "        shapefile_layer_name = layer_dict[shapefile_layer_id]\n",
        "        print('Analyzing layer: {}'.format(shapefile_layer_name))\n",
        "        print('Anda dapat beralih ke sel berikutnya.')\n",
        "      except:\n",
        "        print(\"We couldn't find that layer ID. Please try again.\")\n",
        "except:\n",
        "  print(\"We couldn't find that dataset ID. Please try again.\")\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33jFLNmf2eY5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "#@markdown ## **Search for Your Boundary Area by ID**\n",
        "#@markdown If you are doing a national-level analysis, enter the ISO3 code for the country of interest. You will easily find the ISO3 code by googling \"ISO3 code for\" followed by the name of the country. In Indonesia, for example, the ISO3 code is IDN.\n",
        "#@markdown\n",
        "#@markdown If you are doing analysis for another shapefile dataset on Resource Watch, first, open the dataset that contains your boundary area of interest on the Resource Watch map. Click on the boundary area that you want to analyze data within, copy the Area ID from the window that pops up, and paste it in the 'area_id' field below.\n",
        "#@markdown ###Please idenitfy the boundary area where you would like to summarize data by entering its name in the area_name field OR the Area ID from the interaction in the area_id field. Then, push the play button on the left.\n",
        "orig_geo_id=None\n",
        "\n",
        "url_len = 2000 #5400\n",
        "def simplification_factor_picker(best_simple, best_len, SIMPLE_I, best_simple_high, best_len_high, lowest_simple, highest_simple):\n",
        "  SIMPLE_I+=1\n",
        "  #first we will sample a range of simplificaiton factors\n",
        "  if SIMPLE_I==1:\n",
        "    simplification_factor=0.01\n",
        "  elif SIMPLE_I==2:\n",
        "    simplification_factor=0.05\n",
        "  elif SIMPLE_I==3:\n",
        "    simplification_factor=0.1\n",
        "  elif SIMPLE_I==4:\n",
        "    simplification_factor=0.5\n",
        "  #next we will narrow down the simplification factor between the best two solutions\n",
        "  else:\n",
        "    if not best_simple:\n",
        "      simplification_factor = highest_simple + 0.1\n",
        "    elif not best_simple_high:\n",
        "      simplification_factor = lowest_simple - 0.001\n",
        "    else:\n",
        "      low_int = int(best_simple_high*10000)\n",
        "      high_int = int(best_simple*10000)\n",
        "      #print('generating a random number between {} and {}'.format(low_int, high_int))\n",
        "      simplification_factor = random.randint(low_int,high_int)/10000\n",
        "  #print('trying {}'.format(simplification_factor))\n",
        "  return simplification_factor, SIMPLE_I\n",
        "\n",
        "def simplification_algorithm(current_simple, current_len, shapefile_dataset_id, table, cartodb_id):\n",
        "  SIMPLE_I = 0\n",
        "  best_len = 0\n",
        "  best_len_high = np.inf\n",
        "  best_simple = None\n",
        "  best_simple_high = None\n",
        "  lowest_simple = np.inf\n",
        "  highest_simple = 0\n",
        "  print('Simplifying geometry...', end=\"\")\n",
        "  while SIMPLE_I<20 or (best_len<(url_len-1000) and SIMPLE_I<40):\n",
        "    if SIMPLE_I <20:\n",
        "      if SIMPLE_I<19:\n",
        "        print('{}%...'.format(SIMPLE_I*5), end=\"\")\n",
        "      else:\n",
        "        print('{}%...'.format(SIMPLE_I*5))\n",
        "    elif SIMPLE_I==20:\n",
        "      print('This boundary area is very complicated...simplifying further...')\n",
        "    current_simple, SIMPLE_I = simplification_factor_picker(best_simple, best_len, SIMPLE_I, best_simple_high, best_len_high, lowest_simple, highest_simple)\n",
        "    try:\n",
        "      geo_id, feature = return_simplified_geometries(shapefile_dataset_id, table, cartodb_id, current_simple)\n",
        "    except:\n",
        "      continue\n",
        "    if current_simple < lowest_simple:\n",
        "      lowest_simple = current_simple\n",
        "      #print('lowest_simple: {}'.format(lowest_simple))\n",
        "    if current_simple > highest_simple:\n",
        "      highest_simple = current_simple\n",
        "      #print('highest_simple: {}'.format(highest_simple))\n",
        "    current_len = len(str(feature))\n",
        "    #print('Round {}, simplification factor: {}, length: {}'.format(SIMPLE_I, current_simple, current_len))\n",
        "\n",
        "    if current_len < url_len and current_len > best_len:\n",
        "      #print('New best feature!')\n",
        "      best_len = current_len\n",
        "      best_simple = current_simple\n",
        "      best_geo_id = geo_id\n",
        "      best_feature = feature\n",
        "    elif current_len > url_len and current_len < best_len_high:\n",
        "      #print('New best feature (high)!')\n",
        "      best_len_high = current_len\n",
        "      best_simple_high = current_simple\n",
        "  return best_geo_id, best_feature, best_simple, best_len\n",
        "\n",
        "def get_table_name(shapefile_layer_id):\n",
        "  url= 'https://api.resourcewatch.org/layer/{shapefile_layer_id}'.format(shapefile_layer_id=shapefile_layer_id)\n",
        "  r = requests.get(url)\n",
        "  layer_sql = r.json()['data']['attributes']['layerConfig']['body']['layers'][0]['options']['sql']  \n",
        "  list_of_words = layer_sql.split()\n",
        "  indices = [i for i, x in enumerate(list_of_words) if x == \"FROM\"]\n",
        "  possible_tables = []\n",
        "  for idx in indices:\n",
        "    next_word = list_of_words[idx + 1]\n",
        "    if \"select\" not in next_word.lower():\n",
        "      possible_tables.append(next_word)\n",
        "  if len(np.unique(possible_tables))==1:\n",
        "    table = np.unique(possible_tables)[0]\n",
        "    carto_account = r.json()['data']['attributes']['layerConfig']['account']\n",
        "  else:\n",
        "    print(\"Sorry, we are having trouble finding the shapefiles for this layer. Please report the dataset you are searching for to amelia.snyder@wri.org so that she can fix this!\")\n",
        "    table = \"\"\n",
        "  return table, carto_account\n",
        "\n",
        "def return_geometries(table, carto_account, cartodb_id):\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "  }\n",
        "  params_rw=json.dumps({\n",
        "      \"provider\":{\n",
        "          \"type\": \"carto\",\n",
        "          \"table\": table,\n",
        "          \"user\": carto_account,\n",
        "          \"filter\": \"cartodb_id={}\".format(cartodb_id)\n",
        "      }\n",
        "  })\n",
        "  r = requests.post('https://api.resourcewatch.org/v1/geostore/', data=params_rw, headers=headers)\n",
        "  geo_id=r.json()['data']['id']\n",
        "  feature = json.dumps(r.json()['data']['attributes']['geojson']['features'][0]['geometry'])\n",
        "  return geo_id, feature\n",
        "\n",
        "def return_simplified_geometries(shapefile_dataset_id, table, cartodb_id, simplification_factor):\n",
        "  sql_statement = \"SELECT ST_AsText(ST_Simplify(the_geom, {simpl})) as the_geom FROM {table} WHERE cartodb_id={cartodb_id}\".format(table=table, cartodb_id=cartodb_id, simpl=simplification_factor)\n",
        "  url= 'https://api.resourcewatch.org/query/{dataset_id}?sql={sql}'.format(dataset_id=shapefile_dataset_id, sql=urllib.parse.quote(sql_statement))\n",
        "  r = requests.get(url)\n",
        "  geom_wkt_str=r.json()['data'][0]['the_geom']\n",
        "  wkt = shapely.wkt.loads(geom_wkt_str)\n",
        "  g = LMIPy.Geometry(s=wkt)\n",
        "  geo_id = g.id\n",
        "  feature = geojson.Feature(geometry=wkt, properties={}).geometry\n",
        "  return geo_id, feature\n",
        "\n",
        "if shapefile_dataset_id!=\"\" and shapefile_layer_id!=\"\":\n",
        "  area_id = \"\"#@param {type:\"string\"}\n",
        "  area_id = area_id.strip()\n",
        "  #area_name = \"\"#@param {type:\"string\"}\n",
        "  #area_name = area_name.strip()\n",
        "  if area_id == \"\":\n",
        "    print('Please enter the area ID of the area you want to analyze.')\n",
        "  else:\n",
        "    if country_analysis == 'Y':\n",
        "      area_name = area_id\n",
        "      print('Searching for {area}...'.format(area=area_name))\n",
        "      try:\n",
        "        url = 'https://api.resourcewatch.org/v2/geostore/admin/{iso}'.format(iso=area_name)\n",
        "        r=requests.get(url)\n",
        "        feature = json.dumps(r.json()['data']['attributes']['geojson']['features'][0]['geometry'])\n",
        "        geo_id=r.json()['data']['id']\n",
        "        print('We found it!')\n",
        "        orig_geo_id = geo_id\n",
        "        feature_len = len(str(feature))\n",
        "        simplification_factor = 0\n",
        "        if feature_len>url_len:\n",
        "          table = 'wri_countries_a'\n",
        "          sql_statement = \"SELECT * FROM {table} WHERE iso_a3='{iso}'\".format(table=table, iso=area_name)\n",
        "          ds_id = '20662342-dcdd-4a42-9f58-bcc80217de71'\n",
        "          url= 'https://api.resourcewatch.org/query/{dataset_id}?sql={sql}'.format(dataset_id=ds_id, sql=urllib.parse.quote(sql_statement))\n",
        "          r = requests.get(url)\n",
        "          df=pd.DataFrame(r.json()['data'])\n",
        "          cartodb_id = df.loc[0, 'cartodb_id']\n",
        "          geo_id, feature, simplification_factor, feature_len = simplification_algorithm(simplification_factor, feature_len, ds_id, table, cartodb_id)\n",
        "        #print('final simplification factor: {}, final url length: {}'.format(simplification_factor, feature_len))\n",
        "        if len(str(feature))<=url_len:\n",
        "          print('Your boundary area has been successfully processed.')\n",
        "          print('You can move on to the next cell.')\n",
        "      except:\n",
        "        print(\"We couldn't find {area}. Please check your ISO3 code and start over.\".format(area=area_name))\n",
        "    else:\n",
        "      table, carto_account = get_table_name(shapefile_layer_id)\n",
        "      if area_id!=\"\":\n",
        "        try:\n",
        "          int(area_id)\n",
        "        except Exception as e:\n",
        "          print(\"Please make sure you entered the boundary area's name in the area_name field (not the area_id field).\")\n",
        "          raise StopExecution\n",
        "        cartodb_id=area_id\n",
        "        print('Searching for area ID {area} in {shp_name}...'.format(area=area_id, shp_name=shapefile_layer_name))\n",
        "      elif area_name!=\"\":\n",
        "        print('Searching for {area} in {shp_name}...'.format(area=area_name, shp_name=shapefile_layer_name))\n",
        "        sql_statement = \"SELECT * FROM {table} LIMIT 1\".format(table=table)\n",
        "        url= 'https://api.resourcewatch.org/query/{dataset_id}?sql={sql}'.format(dataset_id=shapefile_dataset_id, sql=urllib.parse.quote(sql_statement))\n",
        "        r = requests.get(url)\n",
        "        df_full=pd.DataFrame(r.json()['data'])\n",
        "        cols = df_full.columns\n",
        "        cols = cols.drop('the_geom').drop('the_geom_webmercator')\n",
        "        sql_statement = \"SELECT {cols} FROM {table}\".format(cols=\", \".join(cols), table=table)\n",
        "        url= 'https://api.resourcewatch.org/query/{dataset_id}?sql={sql}'.format(dataset_id=shapefile_dataset_id, sql=urllib.parse.quote(sql_statement))\n",
        "        r = requests.get(url)\n",
        "        df_full=pd.DataFrame(r.json()['data'])\n",
        "        try:\n",
        "          area_rows = df_full[df_full.eq(area_name).any(1)]\n",
        "          indices = area_rows.index.tolist()\n",
        "          if len(indices)>1:\n",
        "            print('Please choose the cartodb_id for the area that you are interested in from the table below:')\n",
        "            display(area_rows)\n",
        "            cartodb_id = int(input(\"Which cartodb_id would you like to use?\"))\n",
        "          else:\n",
        "            index = area_rows.index.tolist()[0]\n",
        "            cartodb_id = area_rows.loc[index, 'cartodb_id']\n",
        "          print('We found it!')\n",
        "        except:\n",
        "          print(\"We couldn't find that area. Check the name of your region and try again.\")\n",
        "          raise StopExecution\n",
        "      try:\n",
        "        geo_id, feature = return_geometries(table, carto_account, cartodb_id)\n",
        "        orig_geo_id = geo_id\n",
        "        feature_len = len(str(feature))\n",
        "        simplification_factor = 0\n",
        "        if feature_len>url_len:\n",
        "          geo_id, feature, simplification_factor, feature_len = simplification_algorithm(simplification_factor, feature_len, shapefile_dataset_id, table, cartodb_id)\n",
        "        #print('final simplification factor: {}, final url length: {}'.format(simplification_factor, feature_len))\n",
        "      except:\n",
        "        print('This boundary area is too complex to pull from the API. Simplifying boundary area. This may take a few minutes...')\n",
        "        feature_len=999999999\n",
        "        simplification_factor = 0.05\n",
        "        geo_id, feature, simplification_factor, feature_len = simplification_algorithm(simplification_factor, feature_len, shapefile_dataset_id, table, cartodb_id)\n",
        "        #print('final simplification factor: {}, final url length: {}'.format(simplification_factor, feature_len))\n",
        "      if len(str(feature))<=url_len:\n",
        "        print('Your boundary area has been successfully processed.')\n",
        "        print('Anda dapat beralih ke sel berikutnya.')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga3qddmXvZ_K",
        "colab_type": "text"
      },
      "source": [
        "##Map the Boundary Area and Simplification\n",
        "\n",
        "If your boundary area was simplified, you can use the next two cells to see the original boundary area compared to the simplified boundary area. Please note that the simplified boundaries may miss some data points within the region or include data points that actually fall outside of the region. You should pay close attention to data points near the edges of the boundary areas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV45FqLfgH5j",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ##Map the Original Boundary Area\n",
        "#@markdown ###Push the play button on the left to see the original boundary area.\n",
        "if shapefile_dataset_id=='national':\n",
        "  g = LMIPy.Geometry(id_hash=orig_geo_id)\n",
        "  display(g.map())\n",
        "else:\n",
        "  ly = LMIPy.Layer(id_hash=shapefile_layer_id)\n",
        "  try:\n",
        "    g = LMIPy.Geometry(id_hash=orig_geo_id)\n",
        "    display(ly.map(geometry=g))\n",
        "  except Exception as e:\n",
        "    print(\"We couldn't pull the original boundary area from the API because it was too complex. If you would like to see what it looks like, /nplease view it on Resource Watch.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmCEy5JmgLWR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ##Map the Simplified Boundary Area\n",
        "#@markdown ###Push the play button on the left to see the simplified boundary area that we will use for our intersection query.\n",
        "if shapefile_dataset_id=='national':\n",
        "  g = LMIPy.Geometry(id_hash=geo_id)\n",
        "  if simplification_factor==0:\n",
        "    print(\"We did not have to simplify your boundary area. The original area will be used for the analysis.\")\n",
        "  else:\n",
        "    display(g.map())\n",
        "else:\n",
        "  ly = LMIPy.Layer(id_hash=shapefile_layer_id)\n",
        "  g = LMIPy.Geometry(id_hash=geo_id)\n",
        "  if simplification_factor==0:\n",
        "    print(\"We did not have to simplify your boundary area. The original area will be used for the analysis.\")\n",
        "  else:\n",
        "    display(ly.map(geometry=g))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzHXVVNAKH9s",
        "colab_type": "text"
      },
      "source": [
        "#Analyze Data with an SQL Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVbWUhh1leH5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ##Choose a Vector Dataset to Analyze\n",
        "#@markdown Please enter the dataset ID for the vector dataset that you want to analyze using SQL queries. \n",
        "#@markdown \n",
        "#@markdown Here are some example vector dataset IDs:\n",
        "#@markdown \n",
        "#@markdown *  Gini Index: GINI-Index\n",
        "#@markdown *  Global Power Plant Database: a86d906d-9862-4783-9e30-cdb68cd808b8\n",
        "#@markdown *  Fires: VIIRS-Active-Fire-Global-1490086842549\n",
        "#@markdown *  Endangered Species Critical Habitats: bio001-Alliance-for-Zero-Extinction-Endangered-Species-Sites\n",
        "#@markdown *  City Expansion Index: cit037-Upward-and-Outward-Expansion-Index\n",
        "#@markdown \n",
        "#@markdown ###Please enter the dataset ID for the vector dataset you want to analyze, then push the play button on the left to see available columns from the dataset and their descriptions.\n",
        "dataset_id = None\n",
        "#layer_id = None\n",
        "#layer_name = None\n",
        "ds_name = None\n",
        "try:\n",
        "  #Get vector dataset\n",
        "  dataset_id = \"\" #@param {type:\"string\"}\n",
        "  dataset_id = dataset_id.strip()\n",
        "  country_analysis = 'N'\n",
        "  if dataset_id == ('de452a4c-a55c-464d-9037-8c3e9fe48365' or 'World-Database-on-Protected-Areas-Global-1490086842549'):\n",
        "    wdpa = 'Y'\n",
        "  else:\n",
        "    wdpa = 'N'\n",
        "  #Get name from raster dataset\n",
        "  url = 'https://api.resourcewatch.org/dataset/'+dataset_id+'?includes=layer,metadata'\n",
        "  r = requests.get(url)\n",
        "  analysis_carto_account = r.json()['data']['attributes']['connectorUrl'].split('/')[2].split('.')[0]\n",
        "  analysis_carto_table = r.json()['data']['attributes']['connectorUrl'].split('/')[4]\n",
        "  for ds in r.json()['data']['attributes']['metadata']:\n",
        "    if ds['attributes']['application']=='rw':\n",
        "      ds_name = ds['attributes']['name']\n",
        "  print('Analyzing dataset: {}'.format(ds_name))\n",
        "  #pull out the columns in the actual dataset\n",
        "  query = \"SELECT * FROM {table} LIMIT 1\".format(table=dataset_id)\n",
        "  sql_query = urllib.parse.quote(query)\n",
        "  url = 'https://api.resourcewatch.org/query?sql={}'.format(sql_query)\n",
        "  r = requests.get(url)\n",
        "  df_full=pd.DataFrame(r.json()['data'])\n",
        "  cols_to_use = df_full.columns\n",
        "  cols_to_drop = ['the_geom', 'the_geom_webmercator', 'cartodb_id']\n",
        "  for col in cols_to_drop:\n",
        "    if col in cols_to_use:\n",
        "      cols_to_use = cols_to_use.drop(col)\n",
        "  #get aliases and descriptions\n",
        "  url = 'https://api.resourcewatch.org/dataset/'+dataset_id+'?includes=metadata'\n",
        "  r = requests.get(url)\n",
        "  columns = ''\n",
        "  \n",
        "  if r.status_code == 200:\n",
        "    try:\n",
        "      for ds in r.json()['data']['attributes']['metadata']:\n",
        "        if ds['attributes']['application']=='rw':\n",
        "          columns = ds['attributes']['columns']\n",
        "      #Generate DataFrame from columns\n",
        "      #This line also replaces the 'NaN' values with '-'\n",
        "      columns_df = pd.DataFrame.from_dict(columns).replace(np.nan, '-', regex=True)\n",
        "      aliased_columns = columns_df.columns\n",
        "      for col in cols_to_use:\n",
        "        if col not in aliased_columns:\n",
        "          columns_df[col]=['-' for i in range(columns_df.shape[0])]\n",
        "      columns_df=columns_df[cols_to_use]\n",
        "      #Replace Index names with easy to understand names\n",
        "      if set(columns_df.index.values) == set(['alias','description']):\n",
        "        new_names = {'alias':'Plain Text Name:','description':'Column Description:'}\n",
        "        columns_df.rename(index=new_names, inplace=True)\n",
        "      elif set(columns_df.index.values) == set(['alias']):\n",
        "        new_names = {'alias':'Plain Text Name:'}\n",
        "        columns_df.rename(index=new_names, inplace=True)\n",
        "      elif set(columns_df.index.values) == set(['description']):\n",
        "        new_names = {'description':'Column Description:'}\n",
        "        columns_df.rename(index=new_names, inplace=True)\n",
        "        \n",
        "      #Add a new row that has the names of the columns available to use in SQL\n",
        "      sql_columns_row = dict(zip(list(columns_df), list(columns_df)))\n",
        "      new_row_name = 'Columns to Use in SQL'\n",
        "      sql_columns_df = pd.DataFrame(sql_columns_row, index=[new_row_name])\n",
        "      #Make that row the first one\n",
        "      final_df = pd.concat([sql_columns_df, columns_df], ignore_index=False)\n",
        "      #Change the column names so they're blank\n",
        "      final_df.columns = [''] * len(final_df.columns)\n",
        "      #final_df.style.applymap('font-weight: bold',subset=pd.IndexSlice[final_df.index[final_df.index==new_row_name], :])\n",
        "  \n",
        "      \n",
        "      #Finally display the columns!\n",
        "      print('Information on available columns is shown below:')\n",
        "      display(final_df)\n",
        "      print('Use the information above to decide what columns are useful to you.')\n",
        "      print('Anda dapat beralih ke sel berikutnya.')\n",
        "      \n",
        "    #Catch error if we don't know the source\n",
        "    except:\n",
        "      print('Something went wrong. Double check your dataset ID!')\n",
        "      \n",
        "  #Catch 404 Error which is usually the wrong dataset ID\n",
        "  elif r.status_code == 404:\n",
        "    json_err = r.json()\n",
        "    for ds in json_err['errors']:\n",
        "      print(ds['detail'])\n",
        "      print('Double check that your dataset ID is correct!')\n",
        "    \n",
        "  #Catch other error that could happen!\n",
        "  else:\n",
        "    json_err = r.json()\n",
        "    for ds in json_err['errors']:\n",
        "      print(ds['detail'])\n",
        "  '''\n",
        "  #Get layers from shapefile dataset\n",
        "  print('Available layers for '+ds_name +' dataset:')\n",
        "  layer_dict = dict()\n",
        "  layers = r.json()['data']['attributes']['layer']\n",
        "  for layer in layers:\n",
        "    if layer['attributes']['application']==['rw']:\n",
        "      layer_name = layer['attributes']['name']\n",
        "      layer_id =  layer['id']\n",
        "      layer_dict[layer_id]=layer_name\n",
        "      print('     '+layer_id + '  '+layer_name)\n",
        "  layer_id = \"f9029b9a-a435-4d5f-9800-7440db013ada\"#add param here\n",
        "  if layer_id==\"\":\n",
        "    print(\"Please enter a layer ID from these options, and push play again.\")\n",
        "  else:\n",
        "    try:\n",
        "      layer_id=layer_id.strip()\n",
        "      layer_name = layer_dict[layer_id]\n",
        "      print('Analyzing layer: {}'.format(layer_name))\n",
        "    except:\n",
        "      print(\"We couldn't find that layer ID. Please try again.\")\n",
        "   '''\n",
        "except:\n",
        "  print(\"We couldn't find that dataset ID. Please try again.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLp5UlffdZzR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ##Build Your SQL Query\n",
        "#@markdown Berikut adalah tinjauan singkat SQL queries yang telah dipelajari:\n",
        "\n",
        "#@markdown **Lihat semua atau beberapa kolom dataset dengan query dasar**: SELECT {columns} FROM {dataset_id}<br>\n",
        "#@markdown **Batasi jumlah baris yang Anda lihat dari dataset**: SELECT {columns} FROM {dataset_id} LIMIT {number_of_rows}<br>\n",
        "#@markdown **Memfilter data pada beberapa kolom**: SELECT {columns} FROM {table_name} WHERE {column_name} {<, <=, >, >=, =, !=} {value}<br>\n",
        "#@markdown &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Menerapkan beberapa filter**: SELECT {columns} FROM {dataset_id} WHERE {condition1} AND {condition2} AND {condition3}<br>\n",
        "#@markdown &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Filter waktu**: SELECT {columns} FROM {dataset_id} WHERE {datetime_column} {<, <=, >, >=, =, !=} {YYYY-MM-DD}T{HH:MI:SS}Z<br>\n",
        "#@markdown **Mengurutkan dataset berdasarkan dari nilai terbesar atau terkecil**: SELECT {columns} FROM {dataset_id} ORDER BY {column_name} {ASC, DESC}<br>\n",
        "#@markdown **Statistik**: SELECT {function}({column_name}) FROM {dataset_id}<br>\n",
        "#@markdown &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Fungsi Statistik yang tersedia**: AVG(), SUM(), MIN(), MAX(), COUNT()\n",
        "\n",
        "class StopExecution(Exception):\n",
        "  def _render_traceback_(self):\n",
        "    pass\n",
        "#@markdown ###Enter your API query below and run this SQL code to see the result.\n",
        "query =\"\" #@param {type:\"string\"}\n",
        "#@markdown Check the box below if you only want to query data in a particular boundary area of interest, rather than the whole dataset.\n",
        "\n",
        "#@markdown In order to use the boundary area intersection feature, you must complete the **Querying Data within a Boundary Area** section above. Please note that only point data (not polygons) can be analyzed with this feature.\n",
        "\n",
        "boundary_area_intersection = False #@param {type:\"boolean\"}\n",
        "if boundary_area_intersection == True:\n",
        "  try:\n",
        "    geo_query = \"st_intersects(st_setsrid(ST_GeomFromGeoJSON('{geo_json}'), 4326), the_geom) \".format(geo_json=feature)\n",
        "    if 'WHERE' in query:\n",
        "      start = query.split('WHERE')[0]\n",
        "      end = query.split('WHERE')[1]\n",
        "      ending_keyword = ''\n",
        "      where_ends = ['ORDER BY', 'LIMIT']\n",
        "      if any(keyword  in end for keyword in where_ends):\n",
        "        low_idx = np.inf\n",
        "        for keyword in where_ends:\n",
        "          if keyword in end:\n",
        "            if end.index(keyword) < low_idx:\n",
        "              low_idx = end.index(keyword)\n",
        "              ending_keyword = keyword\n",
        "        where_clause = end.split(ending_keyword)[0]\n",
        "        ending_clause = ending_keyword+ end.split(ending_keyword)[1]\n",
        "        query = start + 'WHERE ' + where_clause + ' AND ' + geo_query + ending_clause\n",
        "      else:\n",
        "        query = start + 'WHERE ' + end + ' AND ' + geo_query\n",
        "    else:\n",
        "      query =  query + ' WHERE ' + geo_query\n",
        "  except Exception as e:\n",
        "    if 'feature' in str(e):\n",
        "      print('You have not properly defined your boundary area. Please complete the \"Querying Data within a Specific Boundary Area\" section above.')\n",
        "      raise StopExecution\n",
        "sql_query = urllib.parse.quote(query)\n",
        "url = 'https://api.resourcewatch.org/query?sql={}'.format(sql_query)\n",
        "print('Data Query Link: {}'.format(url))\n",
        "download_url = 'https://api.resourcewatch.org/download?sql={}'.format(sql_query)\n",
        "\n",
        "\n",
        "try:\n",
        "  r = requests.get(url)\n",
        "  if r.status_code >= 400:\n",
        "    json_err = r.json()\n",
        "except Exception as e:\n",
        "  print('Something went wrong. Please try running this cell again.')\n",
        "  print('If you continue to get this error, try limiting your request by adding a LIMIT to the end.')\n",
        "  raise StopExecution\n",
        "if r.status_code >= 500:\n",
        "  for ds in json_err['errors']:\n",
        "    print('Please check that your dataset ID is correct.')\n",
        "    raise StopExecution\n",
        "    #print('HTML Error: {}'.format(ds['detail']))\n",
        "elif r.status_code >= 400 and r.status_code < 500:\n",
        "  for ds in json_err['errors']:\n",
        "    print('Please check that your dataset ID and SQL Query are correct.') \n",
        "    raise StopExecution\n",
        "    #print('HTML Error: {}'.format(ds['detail']))\n",
        "elif r.ok:\n",
        "  df = pd.DataFrame.from_dict(r.json()['data'])\n",
        "  if not df.empty:\n",
        "    print('Data Download Link: {}'.format(download_url))\n",
        "    print(\"Results of query:\")\n",
        "    display(df)\n",
        "  else:\n",
        "    print('No data points matched your query.')\n",
        "else:\n",
        "  print('HTML Error: {}'.format(r.status_code))\n",
        "  raise StopExecution\n",
        "if boundary_area_intersection and not df.empty:\n",
        "  if simplification_factor>0:\n",
        "    print('\\nYou have used our boundary area intersection feature.\\nThis tool had to simplify the boundary area to produce these results, meaning that the results are only approximate.\\nIf you would like to publish these results in a news article (or anywhere else), we recommend that you use the following\\nRequest Form to request results using the original boundary area instead of the simplified version that was used here.\\n')\n",
        "    print('     Request Form: https://docs.google.com/forms/d/e/1FAIpQLSfdhiaGTnP7x7pv3N92MhflE7qCRprBse4xB9zvvTG9Zs9G9g/viewform\\n')\n",
        "    print('You will be asked to provide your contact information, the SQL query that you would like us to run, and the Geo ID (below).\\n')\n",
        "    req_id = '{}.{}.{}.{}.{}'.format(shapefile_dataset_id, shapefile_layer_id, analysis_carto_account, analysis_carto_table, cartodb_id)\n",
        "    req_id_encoded=codecs.encode(req_id.encode('utf8'), 'hex').decode('utf8')\n",
        "    print('     Geo ID: {}'.format(req_id_encoded))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}