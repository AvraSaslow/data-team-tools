{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target directory of logged API json files, will create new one if it does not exist\n",
    "data_dir = 'rw_api_archive'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a copy of RW dataset, layer, and widget endpoints. Note 'env' and 'application' params in URL string\n",
    "api_list = ['dataset','layer','widget']\n",
    "\n",
    "for endpoint in api_list:\n",
    "    url = f'http://api.resourcewatch.org/v1/{endpoint}?page[size]=10000&env=production&application=rw'\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()['data']\n",
    "        mb = round(float(r.headers['content-length'])/1e6, 2)\n",
    "    \n",
    "        print(f\"Received {mb} MB\",r.headers['Content-Encoding'], \"file in\",\n",
    "              r.headers['X-Response-Time'],f\"for {endpoint} endpoint\")\n",
    "        d8 = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "        with open(f'{data_dir}/{endpoint}_{d8}.json', 'w') as fp:\n",
    "            json.dump(data, fp)\n",
    "    else:\n",
    "        print(f\"Error retrieving {endpoint} API endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select filename of most recent matching json files in target directory and load as json\n",
    "recent_dataset_dl = max(glob.iglob(f'{data_dir}/datas*.json'), key=os.path.getctime)\n",
    "recent_layer_dl = max(glob.iglob(f'{data_dir}/layer*.json'), key=os.path.getctime)\n",
    "recent_widget_dl = max(glob.iglob(f'{data_dir}/widge*.json'), key=os.path.getctime)\n",
    "\n",
    "with open(recent_dataset_dl) as json_file:\n",
    "    rw_dataset_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_layer_dl) as json_file:\n",
    "    rw_layer_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_widget_dl) as json_file:\n",
    "    rw_widget_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set substring, will search for string across all json objects\n",
    "subs = 'ene_028_access_clean_cooking' #<-- SET SUBSTRING HERE\n",
    "layers_using = [x for x in rw_layer_data if str(x).count(subs) != 0] \n",
    "widgets_using = [x for x in rw_widget_data if str(x).count(subs) != 0] \n",
    "datasets_using = [x for x in rw_dataset_data if str(x).count(subs) != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List ids of all matching objects\n",
    "litems = [datasets_using, layers_using, widgets_using]\n",
    "print(subs)\n",
    "for i, x in enumerate(['datasets', 'layers', 'widgets']):\n",
    "    print(x)\n",
    "    for j in litems[i]:\n",
    "        print('https://resourcewatch.org/admin/data/{}/{}/edit'.format(x, j['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
